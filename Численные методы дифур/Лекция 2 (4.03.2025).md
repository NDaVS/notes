### Основные понятия теории разностных схем
#### Сеточные функции и разностный оператор
$H_0 =\begin{cases}Lu(x) = f(x), x \in G \\ lu(x)=\mu(x) x \in \Gamma \end{cases}$
$\overline{G} = G + \Gamma$
Предположим, что аналитически не решается. Попробуем решить численно с помощью метода конечных разностей.
Решение ищется не во всей области, а на области и сетке.

сетка - $\omega_h$, сетка с границей - $\overline{\omega_h}$

---
Рассмотрим одномерный случай (сеточная функция $y_h(x_k), x_k \in \overline{\omega_h}$)

$\overline{\omega_h} = \{x_k = h \cdot k, k = 0, 1, \dots, N, h \cdot N =0\}$

Вычисления приближенных значений функции в узлах сетки.
##### Оценка точности решения
$u-y_n$ - нельзя записать напрямую, т.к. это элементы  из разных пространст.
Для этого строится проекция $u_h = P_h(u)$ на сетку. И теперь 
$||u_h - y_h||_h$ посчитать уже можно

Условие согласования
$\underset{h \rightarrow 0}{{\lim}} ||*||_h = ||*||_0$

Чаще всего
$||y||_c = \max_{y \in \overline{G}}|y(x)|$

$||y_h||_c = \max_{x_k \in \overline{\omega_h}} |y(x_k)|$

$||y||_{L2} = \left(\int_0^1 y^2(x)dx \right) ^{\frac{1}{2}}$

$||y_h|| = \left(\sum_{i=0}^N h y^2(x_i)\right)^{\frac{1}{2}} = [|y_h|]$

$||y_h|| = \left(\sum_{i=1}^{N-1} h y^2(x_i)\right)^{\frac{1}{2}} = ]|y_h|[$
---
#### Введение новых операторов
$\begin{cases}L_h u_h = \phi_h \\ l_h u_h=\chi_h \end{cases}$


Разностный оператор.
выбирается отрезок (набор точек) и там строется линейная комбинация (Шаблон - Ш).
$L_h u_h(x) = \sum_{\xi \in \text{Ш(x,h)}} A_h(x, \xi)\cdot u_h(\xi)$

---
#### Опроксимация первой производной

$$\frac{u(x+h) - u(x)}{h} (x, x+h)$$ - двухточечный шаблон

---
##### Погрешность аппроксимации в одной точке
$$\psi(x) = L_hu(x) - L u(x)$$
Порядок погрешности
$$\psi(x) = O(h^m)$$ - погрешность аппроксимации

---
##### СЛАУ
$$\begin{cases}L_h u_h = \phi_h \\ l_h u_h=\chi_h \end{cases}$$
Разностной схемой называется семейство уровнений, зависящих от параметра $h$

---
#### Погрешность решения (разностной схемы)
$$z_h = y_h - u_h$$ $u_h$ - проекция 

$$\begin{cases}L_h z_h = \psi_h \\ l_h z_h=\nu_h \end{cases}$$

Если
$$||\psi_h||_{h_1} \overset{h \rightarrow0}{\rightarrow}0$$
$$||\nu_h||_{h_2} \overset{h \rightarrow0}{\rightarrow}0$$

то
$$||\psi_h||_{h_1} = O(h^m)$$
$$||\nu_h||_{h_2} = O(h^m)$$
---
##### Сходимость
$$||z_h||_{h_3}\overset{h \rightarrow0}{\rightarrow}0$$
$$||z_h|| = O(h^m)$$
---
#### Принцип вычмата
- устойчивость
- аппроксимация 
- сходимость
---
#### Устойчивость
Разностная схема устойчива, если выполняется:
$$||y_h||_{h_1} \le M_1 ||\phi_h||_{h_2} + M_2 ||\chi_h||_{h3}$$
где $M_1, M_2$ - константы, не зависящие от $h$

---
#### Сходимость 2 (т. Филиппова)
$$||z_n||_{h_1} = ||y_h - u_h||_{h_1} \le M_1 ||\psi_h||_{h_2} + M_2||\nu_h||_{h_3}$$
Если выполняется неравенство, то мы получаем верхнюю границе погрешности
$$||z_h||\underset{h \rightarrow 0}{\rightarrow}0$$
из аппроксимации и устойчивости следует сходимость.

---
### вывод
$u'(x)$
разность вперёд, назад и посередине
$$\frac{u(x+h) - u(x)}{h} = u'(x) + O(h)$$
$$\frac{u(x) - u(x-h)}{h}= u'(x) + O(h)$$
$$\frac{u(x+h) - u(x-h)}{2h} = u'(x) + O(h^2)$$

доказать
$$u(x+h) = u(x) \pm hu'(x) \pm \frac{h^2}{2}u''(x) \pm \frac{h^3}{6}u'''(x) + O(h^4)$$
Доказать
$$\frac{u(x+h)-2u(x) + u(x-h)}{h^2} = u''(x) + O(h^2)$$
#### схема второй производной
$$\sigma \frac{u(x+h) - u(x)}{h} + (1 -\sigma) \frac{u(x+2h) - u(x+h)}{h} = u'(x) + \frac{h}{2}(3-2\sigma)u''(x) + O(h^2)$$
$\sigma = \frac{3}{2}$
right
$$\frac{4u(x+h) - 3u(x) - u(x+2h)}{2h}$$
left
$$\frac{3u(x) - 4u(x-h)+u(x-2h)}{2h}$$
---
#### диффур
$$\begin{cases}u''(x)+p(x)u'(x) + q(x)u(x) = f(x) \\ \alpha_1 u(0) + \beta_1 u'(0) = \gamma_1 \\ \alpha_2 u(1) + \beta_2 u'(1) = \gamma_2\end{cases}$$
$$\frac{y_{i=1} - 2 y_i + yI{i-1}}{h^2} + p_i\frac{y_{i+1} -y_{i-1}}{2h} + q_iu_i = f_i, i = 1,\dots, N$$
$$\begin{cases} \alpha_1y_0 + \beta_1\frac{y_1 - y_0}{h} = \gamma_1, O(h) \\ \alpha_2y_N + \beta_2\frac{y_N - y_{N-1}}{h} = \gamma_2, O(h)   \end{cases}$$
Теперь можно записать
$$
\begin{cases} \alpha_1y_0 + \beta_1\frac{-3y_0 + 4y_1-y_2}{h} = \gamma_1, O(h^2) \\ \alpha_2y_N + \beta_2\frac{-||-}{h} = \gamma_2, O(h^2)   \end{cases}
$$
$$A = \begin{bmatrix}
    a_1 & b_1 & 0   & 0   & \cdots & 0   \\
    c_1 & a_2 & b_2 & 0   & \cdots & 0   \\
    0   & c_2 & a_3 & b_3 & \cdots & 0   \\
    \vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
    0   & 0   & 0   & c_{n-2} & a_{n-1} & b_{n-1} \\
    0   & 0   & 0   & 0   & c_{n-1} & a_n 
\end{bmatrix}$$
